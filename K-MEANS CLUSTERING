import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Load the data (replace 'productsalesanalysis1.csv' with your actual data file)
data = pd.read_csv('D:\IBM PROJECT\productsalesanalysis1.csv')

# Select relevant features: Product_Name, Profit, and Region
X = data[['Product_Name', 'Profit', 'Region']]

# Convert Product_Name and Region to numerical labels using .loc
X.loc[:, 'Product_Name'] = pd.factorize(X['Product_Name'])[0]
X.loc[:, 'Region'] = pd.factorize(X['Region'])[0]

# Determine the optimal number of clusters (K) using the Elbow method
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

# Plot the Elbow method to find the optimal number of clusters
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of clusters (K)')
plt.ylabel('WCSS (Within-Cluster Sum of Squares)')
plt.show()

# Based on the Elbow plot, let's say K=3 is a good choice
k = 3

# Apply K-Means clustering
kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)
pred_y = kmeans.fit_predict(X)

# Add the cluster labels to the dataset
data['Cluster'] = pred_y

# Print and analyze the clusters
for cluster in range(k):
    cluster_data = data[data['Cluster'] == cluster]
    print(f"Cluster {cluster + 1}:")
    print(cluster_data)

# Visualization of clusters
for cluster in range(k):
    cluster_data = data[data['Cluster'] == cluster]
    plt.scatter(cluster_data['Product_Name'], cluster_data['Profit'], label=f'Cluster {cluster + 1}')

plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red', label='Centroids')
plt.title('Product Profit Clusters')
plt.xlabel('Product Name (Numerical Label)')
plt.ylabel('Profit')
plt.legend()
plt.show()
